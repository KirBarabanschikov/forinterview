{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/avito_train.csv')\n",
    "test = pd.read_csv('data/avito_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>Category_name</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Эбу Renault / Nissan 1,5 DCI Delphi 2001-2008 год</td>\n",
       "      <td>Комплект ЭБУ (мозги, компьютер мотора, двигате...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Утюг утп 1000 ватт СССР 1987 год</td>\n",
       "      <td>Продам/\\n Фото № 1-2 /\\n /\\nУтюг УТП 1000 ватт...</td>\n",
       "      <td>Бытовая техника</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Возвму машину с выкупом</td>\n",
       "      <td>Возьму машину в аренду с последующим выкупом н...</td>\n",
       "      <td>Предложение услуг</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Полусапожки</td>\n",
       "      <td>полусапожки в отличном состоянии, один раз оде...</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Босоножки кожаные</td>\n",
       "      <td>Кожаные(натур) босоножки Karlo Pasolini, 40 рр...</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Эбу Renault / Nissan 1,5 DCI Delphi 2001-2008 год   \n",
       "1                   Утюг утп 1000 ватт СССР 1987 год   \n",
       "2                            Возвму машину с выкупом   \n",
       "3                                        Полусапожки   \n",
       "4                                  Босоножки кожаные   \n",
       "\n",
       "                                         description  \\\n",
       "0  Комплект ЭБУ (мозги, компьютер мотора, двигате...   \n",
       "1  Продам/\\n Фото № 1-2 /\\n /\\nУтюг УТП 1000 ватт...   \n",
       "2  Возьму машину в аренду с последующим выкупом н...   \n",
       "3  полусапожки в отличном состоянии, один раз оде...   \n",
       "4  Кожаные(натур) босоножки Karlo Pasolini, 40 рр...   \n",
       "\n",
       "               Category_name  Category  \n",
       "0      Запчасти и аксессуары        10  \n",
       "1            Бытовая техника        21  \n",
       "2          Предложение услуг       114  \n",
       "3  Одежда, обувь, аксессуары        27  \n",
       "4  Одежда, обувь, аксессуары        27  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4234042, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "description      2\n",
       "Category_name    0\n",
       "Category         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title&description'] = train['title']+' '+train.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Category.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform(np.array(train['title&description']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4234042x2125805 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 150918485 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024524"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.get('утюг')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2043\n"
     ]
    }
   ],
   "source": [
    "quantuty_numeric = 0\n",
    "quantuty_punctuation = 0\n",
    "for key, value in dictionary.items():\n",
    "    if key[0].isnumeric() == True:\n",
    "    # if key.startswith(str(False)) == True:\n",
    "        quantuty_numeric += 1\n",
    "    elif key[0].isalnum() == False:\n",
    "        quantuty_punctuation += 1\n",
    "print(quantuty_numeric, quantuty_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regex = \"^[a-zA-Zа-яА-ЯёЁ1-9]+$\"\n",
    "string = \"яgkegfem/eeуууее\"\n",
    "\n",
    "pattern = re.compile(regex)\n",
    "\n",
    "print(pattern.search(string[0]) is not None) # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_train = train.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_vec = CountVectorizer()\n",
    "try_bow = try_vec.fit_transform(np.array(try_train['title&description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Эбу Renault / Nissan 1,5 DCI Delphi 2001-2008 год Комплект ЭБУ (мозги, компьютер мотора, двигателя, коммутатор). Электронный блок управления двигателем (компьютер мотора) для Рено Kangoo (Канго Кангу), Меган, Сценик, Laguna (Лагуна), Clio (Клио), Nissan Micra (Ниссан Микра) и другие Рено Ниссан 1,5 дизель с топливной аппаратурой Делфи. Б.У. Оригинал, отличное состояние, проверенные с гарантией.\\xa0/\\n /\\n\\xa0............................................................................................./\\n /\\nНа все запчасти предоставляется\\xa0ГАРАНТИЯ, возможна\\xa0установка.\\xa0Более подробно — в разделе «о компании». Мы дорожим своей репутацией и торгуем\\xa0ТОЛЬКО ЛЕГАЛЬНЫМИ\\xa0контрактными запчастями - на все детали в наличии таможенные документы. Все запчасти - от автомобилей\\xa0БЕЗ ПРОБЕГА ПО РОССИИ.\\xa0/\\n /\\n--- -------------------------------------------------------------------------------------------------/\\n /\\nОтправляем в другие регионы Таможенного Союза транспортной компанией или наложным платежом.',\n",
       " 'Утюг утп 1000 ватт СССР 1987 год Продам/\\n Фото № 1-2\\xa0/\\n /\\nУтюг УТП 1000 ватт СССР 1987 год- 350 руб/\\n /\\n\\xa0В рабочем состоянии.\\xa0/\\n /\\nФото № 3\\xa0/\\n /\\nУтюг 1000 ватт СССР - 350 руб/\\n /\\n\\xa0В рабочем состоянии.\\xa0/\\n /\\nФото № 4\\xa0/\\n /\\nУтюг 1000 ватт СССР - 350 руб\\xa0/\\n /\\nВ рабочем состоянии.\\xa0/\\n /\\nФото № 5 Утюг 1000 ватт СССР - 350 руб\\xa0/\\n /\\nВ рабочем состоянии.\\xa0/\\n /\\nФото № 6-7\\xa0/\\n /\\nУтюг Delta DL-405 - 450 руб\\xa0/\\n /\\nВ рабочем состоянии./\\n /\\n\\xa0(УС-2). Личная встреча или отправлю по почте./\\n /\\nФото № 8-10\\xa0/\\n /\\nУтюг 1000 ватт СССР - 350 руб/\\n /\\n\\xa0В рабочем состоянии./\\n /\\n\\xa0(С-5). Личная встреча или отправлю по почте.',\n",
       " 'Возвму машину с выкупом Возьму машину в аренду с последующим выкупом недорогую.У кого есть возможность задать машину ПИШИТЕ СЮДА. Звонок могу не услышать.',\n",
       " 'Полусапожки полусапожки в отличном состоянии, один раз одеваны. натуральный мех. велюр/кожа.',\n",
       " 'Босоножки кожаные Кожаные(натур) босоножки Karlo Pasolini, 40 рр! Б/у 2 раза,в идеальном состоянии!',\n",
       " 'Комбинезон Одет раз',\n",
       " 'Сандали котофей Котофей фирма, на первые шаги. Размер 20',\n",
       " 'Свитер Продаю свитер в идеально состоянии, фирмы benetton, размер 42-44',\n",
       " 'Жакет женский Жакет женский. Новый,с биркой. Торг уместен. Просьба,звонить только вечером ,смс в любое время',\n",
       " 'Стойка передняя правая Opel Corsa C Стойка амортизатора передняя правая на Opel Corsa C 2000-2006./\\n В сборе с пружиной и опорным подшипником./\\n Бу Bilstein./\\n Артикул: 27808641/\\n Даем на все гарантию 14 дней с даты получения запчасти./\\n Забрать запчасть самовывозом можно с 10 до 20 без выходных. Предварительно звоните!/\\n Отправляем запчасти в другие города по предварительной оплате на карту сбербанка или любым другим способом. /\\n Доставка до ТК СДЭК/Байкал-сервис/Энергия/ПЭК/Деловые Линии +500 руб./\\n Пишите вопросы через чат Авито, отвечаем быстро./\\n Звонить можно с 9:00 до 20:30 ежедневно./\\n Есть свой автосервис.',\n",
       " 'Сапоги Paolo Conte Надеты пару раз изначально стоили в разы дороже . Размер 39 ,маломерят .',\n",
       " 'Юбка джинсовая Юбка в хорошем состоянии. Отправляю почтой']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in try_train['title&description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "superiority = [' '.join([stemmer.stem(w) for w in wordpunct_tokenize(t.lower()) if (w.isalpha() and w not in stopwords.words('russian'))]) for t in try_train['title&description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# superiority = [' '.join([stemmer.stem(w) for w in list(set(wordpunct_tokenize(t.lower()))) if (w.isalpha() and w not in stopwords.words('russian'))]) for t in try_train['title&description']]\n",
    "# superiority = [' '.join([stemmer.stem(w) for w in list(OrderedDict.fromkeys(wordpunct_tokenize(t.lower()))) if (w.isalpha() and w not in stopwords.words('russian'))]) for t in try_train['title&description']]\n",
    "# superiority = [' '.join([stemmer.stem(w) for w in wordpunct_tokenize(t.lower()) if (w.isalpha() and stopwords.words('russian').count(w) < 1)]) for t in try_train['title&description']]\n",
    "superiority = [' '.join([stemmer.stem(w) for w in wordpunct_tokenize(t.lower()) if (w.isalpha() and w not in np.array(stopwords.words('russian')))]) for t in try_train['title&description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_vec = CountVectorizer()\n",
    "super_bow = super_vec.fit_transform(superiority)\n",
    "x_train, x_test, y_train, y_test = train_test_split(super_bow, try_train.Category, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x27399 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 263627 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7148"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sgd = SGDClassifier(loss='modified_huber', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "\n",
    "sgd.fit(x_train, y_train)\n",
    "\n",
    "sgd_y_pred = sgd.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, sgd_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7655"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "super_vec = TfidfVectorizer(max_df=0.9)\n",
    "super_bow = super_vec.fit_transform(superiority)\n",
    "x_train, x_test, y_train, y_test = train_test_split(super_bow, try_train.Category, test_size=0.2, random_state=1)\n",
    "\n",
    "sgd = SGDClassifier(loss='modified_huber', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "\n",
    "sgd.fit(x_train, y_train)\n",
    "\n",
    "sgd_y_pred = sgd.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, sgd_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.748"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "super_vec = HashingVectorizer(n_features=30000)\n",
    "super_bow = super_vec.fit_transform(superiority)\n",
    "x_train, x_test, y_train, y_test = train_test_split(super_bow, try_train.Category, test_size=0.2, random_state=1)\n",
    "\n",
    "sgd = SGDClassifier(loss='modified_huber', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "\n",
    "sgd.fit(x_train, y_train)\n",
    "\n",
    "sgd_y_pred = sgd.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, sgd_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
